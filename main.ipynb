{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import prepare_data\n",
    "import svm\n",
    "import aspect_term_feature\n",
    "import aspect_term_polarity_feature\n",
    "import aspect_category_feature\n",
    "import aspect_category_polarity_feature\n",
    "import features\n",
    "import result\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndataPath = os.path.join('..','data')    \\ndata.purifyTrainFile(os.path.join(dataPath,'Restaurants_Train.xml'),os.path.join(dataPath,'restaurants-trial.xml'),os.path.join(dataPath,'restaurants_train_purified.xml'))\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we gotta have to purify their training files, since the supplied training files do contain the test sentences as well (this has to be done only once)\n",
    "'''\n",
    "dataPath = os.path.join('..','data')    \n",
    "data.purifyTrainFile(os.path.join(dataPath,'Restaurants_Train.xml'),os.path.join(dataPath,'restaurants-trial.xml'),os.path.join(dataPath,'restaurants_train_purified.xml'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# read training and test data\n",
    "if prepare_data.useGlove:\n",
    "    prepare_data.readGloveData()\n",
    "prepare_data.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Working on domain: Restaurant ###\n",
      "Train and predict aspects ...\n",
      "Train and predict aspect sentiments ...\n",
      "Train and predict categories ...\n",
      "Train and predict category Sentiments ...\n",
      "Elapsed time: 432.9s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(0,1):\n",
    "    trainData = prepare_data.train[i]\n",
    "    testData = prepare_data.test[i]\n",
    "    print('### Working on domain: ' + prepare_data.domains[i] + ' ###')\n",
    "\n",
    "    # features that can be used by several feature extractors that we use for different classification tasks\n",
    "    featuresCommon = features.Features(prepare_data.train[i])\n",
    "    print('Train and predict aspects ...')\n",
    "    \n",
    "    ### classify aspects of a sentence ###\n",
    "    aspectFeatureExtract = aspect_term_feature.AspectTermFeatures(trainData, featuresCommon)\n",
    "    sequenceClassifier = svm.SVM(2)\n",
    "    sequenceClassifier.train(trainData, aspectFeatureExtract)\n",
    "    sequenceClassifier.predict(testData, aspectFeatureExtract, 'preAspect')\n",
    "\n",
    "    print('Train and predict aspect sentiments ...')\n",
    "    ### classify aspect sentiments of a sentence ###\n",
    "    aspectPolarityFeatureExtract = aspect_term_polarity_feature.AspectTermPolarityFeatures(trainData, featuresCommon)\n",
    "    multiclassClassifier = svm.SVM(1)\n",
    "    multiclassClassifier.train(trainData, aspectPolarityFeatureExtract)\n",
    "    multiclassClassifier.predict(testData, aspectPolarityFeatureExtract, 'preSentAsp')\n",
    "\n",
    "    # Check if categories are defined for current set\n",
    "    if len(trainData['categories']) > 0:\n",
    "        print('Train and predict categories ...')\n",
    "        for currentCategory in trainData['categories']:\n",
    "            categoryFeatureExtract = aspect_category_feature.AspectCategoryFeatures(trainData, featuresCommon, currentCategory)\n",
    "            binaryClassifier = svm.SVM(0)\n",
    "            binaryClassifier.train(trainData, categoryFeatureExtract)\n",
    "            binaryClassifier.predict(testData, categoryFeatureExtract, 'preCat')\n",
    "\n",
    "        print('Train and predict category Sentiments ...')\n",
    "        for currentCategory in trainData['categories']:\n",
    "            categoryPolarityFeatureExtractor = aspect_category_polarity_feature.AspectCategoryPolarityFeatures(trainData, featuresCommon, currentCategory)\n",
    "            multiclassClassifier = svm.SVM(1)\n",
    "            multiclassClassifier.train(trainData, categoryPolarityFeatureExtractor)\n",
    "            multiclassClassifier.predict(testData, categoryPolarityFeatureExtractor, 'preCatSent')\n",
    "\n",
    "    ### evaluate results ###\n",
    "    results.append(result.evaluate(testData))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Elapsed time: \" + str(round(end - start,1)) + \"s\")\n",
    "print()\n",
    "\n",
    "# number to percetage string\n",
    "def n2P (x): return str(round(100*x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################\n",
      "Summary of results:\n",
      "### Aspect Classification ###\n",
      "# Restaurant: 96.68% \t(precision: 86.29%, recall: 83.59%, F1-score: 84.92)\n"
     ]
    }
   ],
   "source": [
    "# print final results\n",
    "print('####################################################################################')\n",
    "print('Summary of results:')\n",
    "# print aspect classification results\n",
    "print('### Aspect Classification ###')\n",
    "for i in range(len(results)):\n",
    "    aspectTerm = results[i]['aspects']\n",
    "    print('# ' + prepare_data.domains[i] + ': ' + n2P(aspectTerm['acc']) + '% \\t(precision: ' + n2P(aspectTerm['prec']) + '%, recall: ' + n2P(aspectTerm['rec']) + '%, F1-score: ' + n2P(aspectTerm['f1']) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Aspect Sentiment Classification ###\n",
      "# Restaurant:\n",
      "# Positive: 96.95% \t(precision: 72.66%, recall: 100.0%, F1-score: 84.16)\n",
      "# Negative: 97.91% \t(precision: 0%, recall: 0.0%, F1-score: 0)\n",
      "# Conflict: (Does not appear in test set)\n",
      "# Neutral: 99.04% \t(precision: 0%, recall: 0.0%, F1-score: 0)\n",
      "# -> Average: 97.96% \t(precision: 24.22%, recall: 33.33%, F1-score: 28.05)\n"
     ]
    }
   ],
   "source": [
    "# print aspect sentiment classification results\n",
    "print('### Aspect Sentiment Classification ###')\n",
    "for i in range(len(results)):\n",
    "    aspectTermPolarity = results[i]['aspSent']\n",
    "    print('# ' + prepare_data.domains[i] + ':')\n",
    "    for j in range(4):\n",
    "        if aspectTermPolarity[j]['acc'] != -1:\n",
    "            print('# ' + prepare_data.sents[j] + ': ' + n2P(aspectTermPolarity[j]['acc']) + '% \\t(precision: ' + n2P(aspectTermPolarity[j]['prec']) + '%, recall: ' + n2P(aspectTermPolarity[j]['rec']) + '%, F1-score: ' + n2P(aspectTermPolarity[j]['f1']) + ')')\n",
    "        else:\n",
    "            print('# ' + prepare_data.sents[j] + ': (Does not appear in test set)')\n",
    "    print('# -> Average: ' + n2P(aspectTermPolarity[4]['acc']) + '% \\t(precision: ' + n2P(aspectTermPolarity[4]['prec']) + '%, recall: ' + n2P(aspectTermPolarity[4]['rec']) + '%, F1-score: ' + n2P(aspectTermPolarity[4]['f1']) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Category Classification ###\n",
      "# Restaurant:\n",
      "# food: 95.0% \t(precision: 97.37%, recall: 90.24%, F1-score: 93.67)\n",
      "# anecdotes/miscellaneous: 95.0% \t(precision: 95.56%, recall: 93.48%, F1-score: 94.51)\n",
      "# ambience: 96.0% \t(precision: 100.0%, recall: 42.86%, F1-score: 60.0)\n",
      "# service: 99.0% \t(precision: 88.89%, recall: 100.0%, F1-score: 94.12)\n",
      "# price: 99.0% \t(precision: 100.0%, recall: 91.67%, F1-score: 95.65)\n",
      "# -> Average: 96.8% \t(precision: 96.36%, recall: 83.65%, F1-score: 87.59)\n"
     ]
    }
   ],
   "source": [
    "# print category classification results\n",
    "print('### Category Classification ###')\n",
    "for i in range(len(results)):\n",
    "    if 'category' in results[i]:\n",
    "        category = results[i]['category']\n",
    "        print('# ' + prepare_data.domains[i] + ':')\n",
    "        j = 0\n",
    "        for currentCategory in results[i]['categories']:\n",
    "            if category[j]['acc'] != -1:\n",
    "                print('# ' + currentCategory + ': ' + n2P(category[j]['acc']) + '% \\t(precision: ' + n2P(category[j]['prec']) + '%, recall: ' + n2P(category[j]['rec']) + '%, F1-score: ' + n2P(category[j]['f1']) + ')')\n",
    "            else:\n",
    "                print('# ' + currentCategory + ': (Does not appear in test set)')\n",
    "            j += 1\n",
    "        print('# -> Average: ' + n2P(category[j]['acc']) + '% \\t(precision: ' + n2P(category[j]['prec']) + '%, recall: ' + n2P(category[j]['rec']) + '%, F1-score: ' + n2P(category[j]['f1']) + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Category Sentiment Classification ###\n",
      "# Restaurant:\n",
      "#    Category: food:\n",
      "#    Positive: 75.61% \t(precision: 75.61%, recall: 100.0%, F1-score: 86.11)\n",
      "#    Negative: 78.05% \t(precision: 0%, recall: 0.0%, F1-score: 0)\n",
      "#    Conflict: 97.56% \t(precision: 0%, recall: 0.0%, F1-score: 0)\n",
      "#    Neutral: (Does not appear in test set)\n",
      "#    -> Average: 83.74% \t(precision: 25.2%, recall: 33.33%, F1-score: 28.7)\n",
      "#    Category: anecdotes/miscellaneous:\n",
      "#    Positive: 60.87% \t(precision: 88.89%, recall: 50.0%, F1-score: 64.0)\n",
      "#    Negative: 86.96% \t(precision: 0%, recall: 0.0%, F1-score: 0)\n",
      "#    Conflict: (Does not appear in test set)\n",
      "#    Neutral: 56.52% \t(precision: 28.57%, recall: 100.0%, F1-score: 44.44)\n",
      "#    -> Average: 68.12% \t(precision: 39.15%, recall: 50.0%, F1-score: 36.15)\n",
      "#    Category: ambience:\n",
      "#    Positive: 71.43% \t(precision: 71.43%, recall: 100.0%, F1-score: 83.33)\n",
      "#    Negative: 71.43% \t(precision: 0%, recall: 0.0%, F1-score: 0)\n",
      "#    Conflict: (Does not appear in test set)\n",
      "#    Neutral: (Does not appear in test set)\n",
      "#    -> Average: 71.43% \t(precision: 35.71%, recall: 50.0%, F1-score: 41.67)\n",
      "#    Category: service:\n",
      "#    Positive: 75.0% \t(precision: 75.0%, recall: 100.0%, F1-score: 85.71)\n",
      "#    Negative: 75.0% \t(precision: 0%, recall: 0.0%, F1-score: 0)\n",
      "#    Conflict: (Does not appear in test set)\n",
      "#    Neutral: (Does not appear in test set)\n",
      "#    -> Average: 75.0% \t(precision: 37.5%, recall: 50.0%, F1-score: 42.86)\n",
      "#    Category: price:\n",
      "#    Positive: 83.33% \t(precision: 81.82%, recall: 100.0%, F1-score: 90.0)\n",
      "#    Negative: 91.67% \t(precision: 100.0%, recall: 50.0%, F1-score: 66.67)\n",
      "#    Conflict: (Does not appear in test set)\n",
      "#    Neutral: 91.67% \t(precision: 0%, recall: 0.0%, F1-score: 0)\n",
      "#    -> Average: 88.89% \t(precision: 60.61%, recall: 50.0%, F1-score: 52.22)\n",
      "# -> Average over all categories:\n",
      "# Positive: 73.25% \t(precision: 78.55%, recall: 90.0%, F1-score: 81.83)\n",
      "# Negative: 80.62% \t(precision: 20.0%, recall: 10.0%, F1-score: 13.33)\n",
      "# Conflict: 97.56% \t(precision: 0.0%, recall: 0.0%, F1-score: 0.0)\n",
      "# Neutral: 74.09% \t(precision: 14.29%, recall: 50.0%, F1-score: 22.22)\n",
      "####################################################################################\n"
     ]
    }
   ],
   "source": [
    "print('### Category Sentiment Classification ###')\n",
    "for i in range(len(results)):\n",
    "    if 'category' in results[i]:\n",
    "        categoryPolarity = results[i]['catSent']\n",
    "        print('# ' + prepare_data.domains[i] + ':')\n",
    "        j = 0\n",
    "        for currentCategory in results[i]['categories']:\n",
    "            print('#    Category: ' + currentCategory + ':')\n",
    "            # for each sentiment\n",
    "            for k in range(4):\n",
    "                if categoryPolarity[j][k]['acc'] != -1:\n",
    "                    print('#    ' + prepare_data.sents[k] + ': ' + n2P(categoryPolarity[j][k]['acc']) + '% \\t(precision: ' + n2P(categoryPolarity[j][k]['prec']) + '%, recall: ' + n2P(categoryPolarity[j][k]['rec']) + '%, F1-score: ' + n2P(categoryPolarity[j][k]['f1']) + ')')\n",
    "                else:\n",
    "                    print('#    ' + prepare_data.sents[k] + ': (Does not appear in test set)')\n",
    "            print('#    -> Average: ' + n2P(categoryPolarity[j][4]['acc']) + '% \\t(precision: ' + n2P(categoryPolarity[j][4]['prec']) + '%, recall: ' + n2P(categoryPolarity[j][4]['rec']) + '%, F1-score: ' + n2P(categoryPolarity[j][4]['f1']) + ')')\n",
    "            j += 1\n",
    "\n",
    "        print('# -> Average over all categories:')\n",
    "        for k in range(4):\n",
    "            print('# ' + prepare_data.sents[k] + ': ' + n2P(categoryPolarity[j][k]['acc']) + '% \\t(precision: ' + n2P(categoryPolarity[j][k]['prec']) + '%, recall: ' + n2P(categoryPolarity[j][k]['rec']) + '%, F1-score: ' + n2P(categoryPolarity[j][k]['f1']) + ')')\n",
    "\n",
    "print('####################################################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
